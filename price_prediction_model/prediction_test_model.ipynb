{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "muslim-louisville",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PowerTransformer, QuantileTransformer, FunctionTransformer, RobustScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from models.prepareData import getData, convertData, calcMinimumMaximum\n",
    "from models.models import linearRegressionModel, PolynomialFeatures, polynomialRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "clean-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = getData('Bán căn hộ chung cư', 'Nguyễn Hữu Thọ', 'Phước Kiển', 'Nhà Bè')\n",
    "# data = getData('Bán căn hộ chung cư', 'Nguyễn Hữu Cảnh', '22', 'Bình Thạnh')\n",
    "# data = getData('Bán đất', 'Trần Văn Giàu', 'Lê Minh Xuân', 'Bình Chánh')\n",
    "# data = getData('Bán đất', 'Vườn Lài', 'An Phú Đông', '12')\n",
    "# data = getData('Bán nhà riêng', 'Quốc Lộ 13', 'Hiệp Bình Phước', 'Thủ Đức')\n",
    "# data = getData('Bán nhà riêng', 'Phạm Văn Chiêu', '9', 'Gò Vấp')\n",
    "# data = getData('Bán nhà riêng', 'Nguyễn Văn Quá', 'Đông Hưng Thuận', '12')\n",
    "# data = getData('Bán nhà riêng', 'Quốc Lộ 13', 'Hiệp Bình Phước', 'Thủ Đức')\n",
    "# data = getData('Bán đất', 'Nguyễn Thị Rành', 'Nhuận Đức', 'Củ Chi')\n",
    "data = getData('Bán đất', 'Tôn Đản', '10', '4')\n",
    "# data = getData('Bán nhà riêng', '3/2', '14', '10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "narrative-deviation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "raising-mentor",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-47c10c0f2830>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpost_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'post_type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mstreet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'street'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ward'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdistrict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'district'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Miniconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Miniconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[1;31m# validate the location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1501\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Miniconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1442\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1443\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1444\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1446\u001b[0m     \u001b[1;31m# -------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "post_type = data['post_type'].iloc[0]\n",
    "street = data['street'].iloc[0]\n",
    "ward = data['ward'].iloc[0]\n",
    "district = data['district'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-european",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data length: \", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-valentine",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(data['area'], data['price'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data:\n",
    "\n",
    "# sort data in post_date order to drop old data has same area:\n",
    "# data = data.sort_values(by=['posted_date'])\n",
    "\n",
    "# Drop duplicates:    \n",
    "# data = data.drop_duplicates(subset='area', keep='last', inplace=False)\n",
    "\n",
    "# Instead of drop duplicates try calc and use its mean value:\n",
    "data = data.groupby(['area'], as_index=False).mean()\n",
    "\n",
    "# sort data in area order:\n",
    "data = data.sort_values(by=['area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-interview",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~(data['area'] < 10)]\n",
    "data = data[~(data['price'] > 200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data length: \", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data into log1p\n",
    "data['area'] = (data['area']).transform(np.log1p)\n",
    "data['price'] = (data['price']).transform(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_mean = np.mean(data['area'])\n",
    "area_std = np.std(data['area'])\n",
    "\n",
    "price_mean = np.mean(data['price'])\n",
    "price_std = np.std(data['price'])\n",
    "\n",
    "data = data[~( (data['area'] < area_mean) & (data['price'] > price_mean) )]\n",
    "data = data[~( (data['area'] > area_mean) & (data['price'] < price_mean - price_std) )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove outliers using box-plot:\n",
    "# while True:\n",
    "#     area_minimum, area_maximum = calcMinimumMaximum(data['area'])\n",
    "#     if (data['area'] > area_minimum).all() and (data['area'] < area_maximum).all():\n",
    "#         break\n",
    "#     else:\n",
    "#         data = data[(data['area'] > area_minimum) & (data['area'] < area_maximum)]\n",
    "\n",
    "# while True:\n",
    "#     price_minimum, price_maximum = calcMinimumMaximum(data['price'])\n",
    "#     if (data['price'] > price_minimum).all() and (data['price'] < price_maximum).all():\n",
    "#         break\n",
    "#     else:\n",
    "#         data = data[(data['price'] > price_minimum) & (data['price'] < price_maximum)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "# area_minimum, area_maximum = calcMinimumMaximum(data['area'])\n",
    "# data = data[(data['area'] > area_minimum) & (data['area'] < area_maximum)]\n",
    "\n",
    "# price_minimum, price_maximum = calcMinimumMaximum(data['price'])\n",
    "# data = data[(data['price'] > price_minimum) & (data['price'] < price_maximum)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data[(data['area'] > 5.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data length: \", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['area'].plot(kind='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-watch",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['price'].plot(kind='box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data length: \", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abstract-bermuda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(data['area'], data['price'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:round(len(data)/2)]\n",
    "# data_2 = data.iloc[round(len(data)/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-morgan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.models import localOutlierFactor\n",
    "data = localOutlierFactor(data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-sender",
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide data into train and test:\n",
    "train_data, test_data = train_test_split(data, test_size=0.3)\n",
    "test_data, validate_data = train_test_split(test_data, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by area column:\n",
    "train_data = train_data.sort_values(by=['area'])\n",
    "test_data = test_data.sort_values(by=['area'])\n",
    "validate_data = validate_data.sort_values(by=['area'])\n",
    "\n",
    "print(\"\\nTrain data length: \", len(train_data))\n",
    "print(\"Test data length: \", len(test_data))\n",
    "print(\"Validate data length: \", len(validate_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-madonna",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert data into numpy\n",
    "X, Y = convertData(data)\n",
    "X_train, Y_train = convertData(train_data)\n",
    "X_test, Y_test = convertData(test_data)\n",
    "X_validate, Y_validate = convertData(validate_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data:\n",
    "\n",
    "# Standard Scaler:\n",
    "\n",
    "# X = StandardScaler().fit_transform(X)\n",
    "# Y = StandardScaler().fit_transform(Y)\n",
    "\n",
    "# X_train = StandardScaler().fit_transform(X_train)\n",
    "# Y_train = StandardScaler().fit_transform(Y_train)\n",
    "\n",
    "# X_test = StandardScaler().fit_transform(X_test)\n",
    "# Y_test = StandardScaler().fit_transform(Y_test)\n",
    "\n",
    "# X_validate = StandardScaler().fit_transform(X_validate)\n",
    "# Y_validate = StandardScaler().fit_transform(Y_validate)\n",
    "\n",
    "\n",
    "# Quantile Transformer:\n",
    "\n",
    "# X = QuantileTransformer(n_quantiles=len(X_train), output_distribution='uniform').fit_transform(X)\n",
    "# Y = QuantileTransformer(n_quantiles=len(Y_train), output_distribution='uniform').fit_transform(Y)\n",
    "\n",
    "# X_train = QuantileTransformer(n_quantiles=len(X_train), output_distribution='uniform').fit_transform(X_train)\n",
    "# Y_train = QuantileTransformer(n_quantiles=len(Y_train), output_distribution='uniform').fit_transform(Y_train)\n",
    "\n",
    "# X_test = QuantileTransformer(n_quantiles=len(X_test), output_distribution='uniform').fit_transform(X_test)\n",
    "# Y_test = QuantileTransformer(n_quantiles=len(X_test), output_distribution='uniform').fit_transform(Y_test)\n",
    "\n",
    "# X_validate = QuantileTransformer(n_quantiles=len(X_validate), output_distribution='uniform').fit_transform(X_validate)\n",
    "# Y_validate = QuantileTransformer(n_quantiles=len(Y_validate), output_distribution='uniform').fit_transform(Y_validate)\n",
    "\n",
    "# Power Transformer:\n",
    "\n",
    "# X = PowerTransformer(method='yeo-johnson').fit_transform(X)\n",
    "# Y = PowerTransformer(method='yeo-johnson').fit_transform(Y)\n",
    "\n",
    "# X_train = PowerTransformer(method='yeo-johnson').fit_transform(X_train)\n",
    "# Y_train = PowerTransformer(method='yeo-johnson').fit_transform(Y_train)\n",
    "\n",
    "# X_test = PowerTransformer(method='yeo-johnson').fit_transform(X_test)\n",
    "# Y_test = PowerTransformer(method='yeo-johnson').fit_transform(Y_test)\n",
    "\n",
    "# X_validate = PowerTransformer(method='yeo-johnson').fit_transform(X_validate)\n",
    "# Y_validate = PowerTransformer(method='yeo-johnson').fit_transform(Y_validate)\n",
    "\n",
    "# Log Transformer:\n",
    "\n",
    "# X = FunctionTransformer(np.log1p).fit_transform(X)\n",
    "# Y = FunctionTransformer(np.log1p).fit_transform(Y)\n",
    "\n",
    "# X_train = FunctionTransformer(np.log1p).fit_transform(X_train)\n",
    "# Y_train = FunctionTransformer(np.log1p).fit_transform(Y_train)\n",
    "\n",
    "# X_test = FunctionTransformer(np.log1p).fit_transform(X_test)\n",
    "# Y_test = FunctionTransformer(np.log1p).fit_transform(Y_test)\n",
    "\n",
    "# X_validate = FunctionTransformer(np.log1p).fit_transform(X_validate)\n",
    "# Y_validate = FunctionTransformer(np.log1p).fit_transform(Y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 4, figsize=(15, 7))\n",
    "ax[0][0].plot(X)\n",
    "ax[0][0].set_title('X')\n",
    "ax[0][1].plot(X_train)\n",
    "ax[0][1].set_title('X_train')\n",
    "ax[0][2].plot(X_test)\n",
    "ax[0][2].set_title('X_test')\n",
    "ax[0][3].plot(X_validate)\n",
    "ax[0][3].set_title('X_validate')\n",
    "\n",
    "ax[1][0].plot(Y)\n",
    "ax[1][0].set_title('Y')\n",
    "ax[1][1].plot(Y_train)\n",
    "ax[1][1].set_title('Y_train')\n",
    "ax[1][2].plot(Y_test)\n",
    "ax[1][2].set_title('Y_test')\n",
    "ax[1][3].plot(Y_validate)\n",
    "ax[1][3].set_title('Y_validate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find model by using linear regression:\n",
    "linear_model = linearRegressionModel(X_train, Y_train)\n",
    "\n",
    "# find Y by using linear model predict:\n",
    "Y_train_pred = linear_model.predict(X_train)\n",
    "Y_test_pred = linear_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE on train and test data:\n",
    "train_linear_rmse = np.sqrt(mean_squared_error(Y_train, Y_train_pred))\n",
    "test_linear_rmse = np.sqrt(mean_squared_error(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-fireplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLinear Regression Model: \")\n",
    "# Plot linear model:\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.scatter(X_train, Y_train, marker='o', color='blue', label='train_data')\n",
    "plt.scatter(X_test, Y_test, marker='o', color='red', label='test_data')\n",
    "plt.scatter(X_validate, Y_validate, marker='o', color='green', label='validate_data')\n",
    "plt.plot(X_train, Y_train_pred, color='black', label='train_model')\n",
    "plt.legend(bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.xlabel('area')\n",
    "plt.ylabel('price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-bulletin",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Linear Model coefficient and intercept:\n",
    "print(\"Linear model coefficient: {}\".format(linear_model.coef_))\n",
    "print(\"Linear model intercept: {}\".format(linear_model.intercept_))\n",
    "\n",
    "# linear_model rmse:\n",
    "print(\"Linear model rmse on train data: {}\".format(train_linear_rmse))\n",
    "print(\"Linear model rmse on test data: {}\".format(test_linear_rmse))\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find model by using polynomial regression:\n",
    "poly_model, degree, validate_rmse = polynomialRegression(X_train, Y_train, X_test, Y_test, X_validate, Y_validate)\n",
    "\n",
    "# transform X and X_test:\n",
    "polynomial_features = PolynomialFeatures(degree=degree)\n",
    "X_train_poly = polynomial_features.fit_transform(X_train)\n",
    "X_test_poly = polynomial_features.fit_transform(X_test)\n",
    "\n",
    "# Try predicting Y\n",
    "Y_train_poly_pred = poly_model.predict(X_train_poly)\n",
    "Y_test_poly_pred = poly_model.predict(X_test_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model:\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.scatter(X_train, Y_train, marker='o', color='blue', label='train_data')\n",
    "plt.scatter(X_test, Y_test, marker='o', color='red', label='test_data')\n",
    "plt.scatter(X_validate, Y_validate, marker='o', color='green', label='validate_data')\n",
    "plt.plot(X_train, Y_train_poly_pred, color='black', label='train_model')\n",
    "plt.legend(bbox_to_anchor=(1,1), loc=\"upper left\")\n",
    "plt.tight_layout()\n",
    "plt.xlabel('area')\n",
    "plt.ylabel('price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Polynomial Regression with degree = {}\\n\".format(degree))\n",
    "# Polynomial Model coefficient and intercept:\n",
    "print(\"Polynomial model coefficient:\")\n",
    "print(poly_model.coef_)\n",
    "print(\"Polynomial model intercept: {}\\n\".format(poly_model.intercept_))\n",
    "\n",
    "# poly_model rmse:\n",
    "# print(\"Polynomial Model RMSE on train data: {}\".format(train_rmse))\n",
    "print(\"Polynomial Model RMSE on validate data: {}\".format(validate_rmse))\n",
    "# print(\"Polynomial Model RMSE on test data: {}\".format(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score the model with test data:\n",
    "\n",
    "# Linear score:\n",
    "print(\"\\n\")\n",
    "\n",
    "linear_train_r2_score = linear_model.score(X_train, Y_train)\n",
    "print(\"Linear Model score on train dataset: \", linear_train_r2_score)\n",
    "\n",
    "linear_test_r2_score = linear_model.score(X_test, Y_test)\n",
    "print(\"Linear Model score on test dataset: \", linear_test_r2_score)\n",
    "\n",
    "# Poly score:\n",
    "print(\"\\n\")\n",
    "\n",
    "poly_train_r2_score = poly_model.score(X_train_poly, Y_train)\n",
    "print(\"Poly Model score on train dataset: \", poly_train_r2_score)\n",
    "\n",
    "poly_test_r2_score = poly_model.score(X_test_poly, Y_test)\n",
    "print(\"Poly Model score on test dataset: \", poly_test_r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesser-congo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc cross validation score of linear to compare with poly for best model selection\n",
    "linear_cv = np.mean(cross_val_score(linear_model, X, Y, cv=5))\n",
    "poly_cv = np.mean(cross_val_score(poly_model, X, Y, cv=5))\n",
    "\n",
    "best_r2_score = linear_test_r2_score if linear_test_r2_score > poly_test_r2_score else poly_test_r2_score\n",
    "best_model = linear_model if linear_cv > poly_cv else poly_model\n",
    "best_degree = 1 if linear_cv > poly_cv else degree\n",
    "\n",
    "print(linear_cv)\n",
    "print(poly_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "post_type = unidecode.unidecode(post_type.lower().replace(\" \", \"\"))\n",
    "street = unidecode.unidecode(street.lower().replace(\" \", \"\"))\n",
    "ward = unidecode.unidecode(ward.lower().replace(\" \", \"\"))\n",
    "district = unidecode.unidecode(district.lower().replace(\" \", \"\"))\n",
    "model_name = post_type + \"_\" + street + \"_\" + ward + \"_\" + district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model after training for later use:\n",
    "from joblib import dump, load\n",
    "\n",
    "if best_r2_score > 0.7:\n",
    "    # Save model:\n",
    "    dump((best_model, best_degree), 'trained\\\\' + model_name + '.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:    \n",
    "    # load model:\n",
    "    loaded_model, loaded_degree = load('trained/' + model_name + \".joblib\")\n",
    "\n",
    "    test_area = np.array([92.00])\n",
    "    test_area = test_area[:, np.newaxis]\n",
    "    test_area = FunctionTransformer(np.log1p).fit_transform(test_area)\n",
    "\n",
    "    if loaded_degree == 1:\n",
    "        predicted_price = loaded_model.predict(test_area)\n",
    "    else:\n",
    "        test_area_poly = PolynomialFeatures(degree=loaded_degree).fit_transform(test_area)\n",
    "        predicted_price = loaded_model.predict(test_area_poly)\n",
    "\n",
    "    print(FunctionTransformer(np.log1p).inverse_transform(predicted_price))\n",
    "except FileNotFoundError:\n",
    "    print(\"Model not found or trained result is low!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
